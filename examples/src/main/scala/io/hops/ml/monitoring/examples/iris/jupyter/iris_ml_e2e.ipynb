{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris ML E2E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>57</td><td>application_1582107121686_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hopsworks0.logicalclocks.com:8088/proxy/application_1582107121686_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://hopsworks0.logicalclocks.com:8042/node/containerlogs/container_e02_1582107121686_0002_01_000001/ml_monitoring__meb10000\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "Tensorflow version 1.14.0"
     ]
    }
   ],
   "source": [
    "import os, uuid, datetime\n",
    "import tensorflow as tf\n",
    "from pyspark.sql import functions as F\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from hops import hdfs, featurestore, model, experiment, tensorboard, constants, util, serving\n",
    "from hops.model import Metric\n",
    "\n",
    "print('Tensorflow version', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names\n",
    "\n",
    "FS_NAME = 'ml_monitoring_featurestore'\n",
    "\n",
    "MODELS_DIR = \"Models/Iris/\"\n",
    "IRIS_RAW_DATA_DIR = \"Raw_Datasets/Iris/\"\n",
    "\n",
    "IRIS_TRAIN_DATASET_NAME = \"iris_train_dataset\"\n",
    "IRIS_FG_NAME = \"iris_train_all_features\"\n",
    "IRIS_FG_DESCRIPTION = \"Iris training dataset with all features\"\n",
    "IRIS_MODEL_NAME=\"Iris\"\n",
    "IRIS_TOPIC_NAME = \"iris_ml_topic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "COL_NAMES = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "SPECIES = ['setosa', 'versicolor', 'virginica']\n",
    "LABEL_NAME = 'species'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 0us/step"
     ]
    }
   ],
   "source": [
    "# download training data to local\n",
    "train_filename = TRAIN_URL.split('/')[-1]\n",
    "train_local_path = os.getcwd() + '/' + train_filename\n",
    "train_path = tf.keras.utils.get_file(train_local_path, TRAIN_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data to hdfs\n",
    "hdfs.copy_to_hdfs(train_local_path, IRIS_RAW_DATA_DIR, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature group with all the features for training\n",
    "\n",
    "# read and cast\n",
    "train_df = spark.read.csv(hdfs.project_path() + IRIS_RAW_DATA_DIR + train_filename, header=True).toDF(*COL_NAMES)\n",
    "train_df = train_df.select(*(F.col(c).cast(\"float\").alias(c) for c in COL_NAMES))\n",
    "\n",
    "print(train_df.show(4))\n",
    "print(train_df.printSchema())\n",
    "\n",
    "# create feature group\n",
    "featurestore.create_featuregroup(train_df, IRIS_FG_NAME,\n",
    "                                 description=IRIS_FG_DESCRIPTION,\n",
    "                                 descriptive_statistics=True,\n",
    "                                 feature_correlation=True,\n",
    "                                 feature_histograms=True,\n",
    "                                 cluster_analysis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect feature group\n",
    "train_fg = featurestore.get_featuregroup(IRIS_FG_NAME)\n",
    "print(train_fg.show(4))\n",
    "print(train_fg.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature training dataset\n",
    "featurestore.create_training_dataset(train_fg, IRIS_TRAIN_DATASET_NAME,\n",
    "                                     data_format=\"tfrecords\",\n",
    "                                     descriptive_statistics=True,\n",
    "                                     feature_correlation=True,\n",
    "                                     feature_histograms=True,\n",
    "                                     cluster_analysis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test data to local\n",
    "test_filename = TEST_URL.split('/')[-1]\n",
    "test_local_path = os.getcwd() + '/' + test_filename\n",
    "test_path = tf.keras.utils.get_file(test_local_path, TEST_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data to hdfs\n",
    "hdfs.copy_to_hdfs(test_local_path, IRIS_RAW_DATA_DIR, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and cast\n",
    "test_hdfs_path = hdfs.project_path() + IRIS_RAW_DATA_DIR + test_filename\n",
    "test_df = spark.read.csv(test_hdfs_path, header=True).toDF(*COL_NAMES)\n",
    "test_df = test_df.select(*(F.col(c).cast(\"float\").alias(c) for c in COL_NAMES))\n",
    "\n",
    "print(test_df.show(4))\n",
    "print(test_df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy preprocessed test data to hdfs\n",
    "def get_prep_path(path, suffix):\n",
    "    point_idx = path.rfind('.')\n",
    "    return path[:point_idx] + suffix + path[point_idx:]\n",
    "\n",
    "point_idx = test_filename.rfind('.')\n",
    "test_prep_dir = test_filename[:point_idx] + \"_prep\"\n",
    "test_prep_hdfs_path = test_hdfs_path[:test_hdfs_path.rfind('/') + 1] + test_prep_dir\n",
    "test_df.write.option(\"header\", \"true\").mode(\"overwrite\").csv(test_prep_hdfs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "EVALUATION_METRIC=\"accuracy\"\n",
    "DATASET_SHUFFLE_BUFF_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size):\n",
    "    \n",
    "    def stack_features_vector_from_dict(row):\n",
    "        label = tf.cast(row.pop(LABEL_NAME), tf.int64) # pop label\n",
    "        labels = tf.one_hot(label, len(SPECIES)) # one hot encoding\n",
    "        features = tf.stack(list(row.values()), axis=1)\n",
    "        return features, labels\n",
    "\n",
    "    def stack_features_vector(features, labels):\n",
    "        features = tf.stack(list(features.values()), axis=1)\n",
    "        labels = tf.one_hot(tf.cast(labels, tf.int64), len(SPECIES))  # one hot encoding\n",
    "        return features, labels\n",
    "    \n",
    "    def decode(pb):\n",
    "        return tf.parse_single_example(pb, tf_record_schema)\n",
    "\n",
    "    # training data\n",
    "    print('Loading training data...')\n",
    "    dataset_dir = featurestore.get_training_dataset_path(IRIS_TRAIN_DATASET_NAME)\n",
    "    input_files = tf.gfile.Glob(dataset_dir + \"/part-r-*\") # the tf records are written in a distributed manner using partitions\n",
    "    tf_record_schema = featurestore.get_training_dataset_tf_record_schema(IRIS_TRAIN_DATASET_NAME) # tf record schemas are managed by the feature store\n",
    "    train_dataset = tf.data.TFRecordDataset(input_files).map(decode).shuffle(DATASET_SHUFFLE_BUFF_SIZE).batch(batch_size).repeat(1).map(stack_features_vector_from_dict)\n",
    "    \n",
    "    # test data\n",
    "    print('Loading test data...')\n",
    "    hdfs.copy_to_local(test_prep_hdfs_path)\n",
    "    test_dataset = tf.data.experimental.make_csv_dataset(test_prep_dir + \"/part-*\", batch_size=batch_size, num_epochs=1, label_name=LABEL_NAME).map(stack_features_vector)\n",
    "    \n",
    "    # n_features, n_classes\n",
    "    features, _ = next(iter(train_dataset))\n",
    "    n_features, n_classes = features.shape[1].value, len(SPECIES)\n",
    "    \n",
    "    return train_dataset, test_dataset, n_features, n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_features, n_classes):\n",
    "    \n",
    "    # nn parameters\n",
    "    n_hidden_1 = 256 # 1st layer number of neurons\n",
    "    n_hidden_2 = 128 # 1st layer number of neurons\n",
    "\n",
    "    # weights\n",
    "    weights = {\n",
    "      'h1': tf.Variable(tf.random_normal([n_features, n_hidden_1]), name='h1'),\n",
    "      'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name='h2'),\n",
    "      'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]), name='wout')\n",
    "    }\n",
    "    \n",
    "    # biases\n",
    "    biases = {\n",
    "      'b1': tf.Variable(tf.random_normal([n_hidden_1]), name='b1'),\n",
    "      'b2': tf.Variable(tf.random_normal([n_hidden_2]), name='b2'),\n",
    "      'out': tf.Variable(tf.random_normal([n_classes]), name='bout')\n",
    "    }\n",
    "    \n",
    "    # forward propagation\n",
    "    def forward_propagation(x):\n",
    "        \n",
    "        # hidden layer 1\n",
    "        layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "        # hidden layer 2\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "        \n",
    "        # output: fully connected layer\n",
    "        out_layer = tf.matmul(layer_2, weights['out']) + biases['out'] \n",
    "        \n",
    "        return out_layer\n",
    "    \n",
    "    return forward_propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(sess, yprobs, X, features, labels, train_conf=None):\n",
    "    \n",
    "    def _accuracy(preds, labels):\n",
    "        matches = tf.equal(tf.argmax(preds, axis=1), tf.argmax(labels, axis=1))\n",
    "        return tf.reduce_mean(tf.cast(matches, \"float\"))\n",
    "    \n",
    "    batch_accuracies = 0\n",
    "    batch_count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            batch_x, batch_y = sess.run([features, labels])\n",
    "            if train_conf is not None:\n",
    "                sess.run(train_conf['train_op'], feed_dict={X: batch_x, train_conf['y']: batch_y}) # train step\n",
    "            preds = sess.run(yprobs, feed_dict={X: batch_x})\n",
    "#             acc, acc_op = tf.metrics.accuracy(labels=tf.argmax(batch_y, axis=1), predictions=tf.argmax(preds, axis=1))\n",
    "            batch_accuracies += _accuracy(preds, batch_y) # batch acc\n",
    "            batch_count += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    if batch_accuracies == 0 or batch_count == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return batch_accuracies / batch_count\n",
    "\n",
    "def train_model(sess, model, train_dataset, test_dataset, n_features, n_classes, hyperparams):\n",
    "    \n",
    "    print('Training model...')\n",
    "\n",
    "    # tensorboard\n",
    "#     summ_writer = tf.summary.FileWriter(tensorboard.logdir() + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), sess.graph)\n",
    "#     with tf.name_scope('performance'):\n",
    "#         test_accuracy_ph = tf.placeholder(tf.float32, shape=None, name='test_accuracy_summary')\n",
    "#         train_accuracy_ph = tf.placeholder(tf.float32, shape=None, name='train_accuracy_summary')\n",
    "#         train_accuracy_summary = tf.summary.scalar('train_accuracy', train_accuracy_ph)\n",
    "#         test_accuracy_summary = tf.summary.scalar('test_accuracy', test_accuracy_ph)\n",
    "#         performance_summaries = tf.summary.merge([train_accuracy_summary, test_accuracy_summary])\n",
    "\n",
    "    # inputs\n",
    "    X = tf.placeholder(\"float\", shape=[None, n_features], name='X') # features\n",
    "    y = tf.placeholder(\"float\", shape=[None, n_classes], name='y') # labels\n",
    "\n",
    "    # ouputs\n",
    "    yhat = model(X) # logits (,n_classes)\n",
    "    yprobs = tf.nn.softmax(yhat) # predictions -> probabilities (,n_classes)\n",
    "    ypreds = tf.argmax(yprobs, axis=1)\n",
    "    yprobs_ordered, idxs = tf.nn.top_k(yprobs, n_classes)\n",
    "    table = tf.contrib.lookup.index_to_string_table_from_tensor(tf.constant([str(i) for i in range(n_classes)]))\n",
    "    ypredict_ordered = table.lookup(tf.to_int64(idxs)) # predictions -> all indexes ordered by probs (,n_classes)\n",
    "    \n",
    "    # backward propagation\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=yhat))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(hyperparams['learning_rate'])\n",
    "    train_op = optimizer.minimize(cost)\n",
    "    \n",
    "    # create iterator and initializers\n",
    "    iter = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "    features, labels = iter.get_next()\n",
    "    train_init_op = iter.make_initializer(train_dataset)\n",
    "    test_init_op = iter.make_initializer(test_dataset)\n",
    "    \n",
    "    for epoch in range(hyperparams['epochs']):\n",
    "        \n",
    "        # training\n",
    "        sess.run(train_init_op) # initialize with training data\n",
    "        epoch_train_accuracy = accuracy(sess, yprobs, X, features, labels, train_conf={'train_op': train_op, 'y': y }) # get accuracy while training\n",
    "        \n",
    "        # epoch testing\n",
    "        sess.run(test_init_op) # switch to test data\n",
    "        epoch_test_accuracy = accuracy(sess, yprobs, X, features, labels) # without training\n",
    "        \n",
    "        # tensorboard\n",
    "#         summ = sess.run(performance_summaries, feed_dict={train_accuracy_summary: epoch_train_accuracy, test_accuracy_summary: epoch_test_accuracy})\n",
    "#         summ_writer.add_summary(summ, epoch)\n",
    "        \n",
    "        print(\"Epoch = %d, train accuracy = %.2f%%, test accuracy = %.2f%%\" % (epoch + 1, 100. * epoch_train_accuracy.eval(), 100. * epoch_test_accuracy.eval()))\n",
    "\n",
    "    # test accuracy\n",
    "    sess.run(test_init_op) # switch to test data\n",
    "    test_accuracy = accuracy(sess, yprobs, X, features, labels)\n",
    "    \n",
    "    return { EVALUATION_METRIC: test_accuracy.eval() }, { 'X': X, 'ypredict_ordered': ypredict_ordered, 'yprobs_ordered': yprobs_ordered, 'ypreds': ypreds }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(sess, metrics, signature):\n",
    "    \n",
    "    export_path = '{}/{}model-{}'.format(os.getcwd(), MODELS_DIR, str(uuid.uuid4()))\n",
    "    print('Exporting trained model to: {}'.format(export_path))\n",
    "    \n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "    # build signature_def_map\n",
    "    clas_inputs = { tf.saved_model.signature_constants.CLASSIFY_INPUTS: tf.saved_model.utils.build_tensor_info(signature['X']) }\n",
    "    clas_outputs = { tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES: tf.saved_model.utils.build_tensor_info(signature['ypredict_ordered']),\n",
    "                     tf.saved_model.signature_constants.CLASSIFY_OUTPUT_SCORES: tf.saved_model.utils.build_tensor_info(signature['yprobs_ordered']) }\n",
    "\n",
    "    classification_signature = (tf.saved_model.signature_def_utils.build_signature_def(\n",
    "                                    inputs=clas_inputs, outputs=clas_outputs,\n",
    "                                    method_name=tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME))\n",
    "\n",
    "    pred_inputs = { tf.saved_model.signature_constants.PREDICT_INPUTS: tf.saved_model.utils.build_tensor_info(signature['X'])}\n",
    "    pred_outputs = { tf.saved_model.signature_constants.PREDICT_OUTPUTS: tf.saved_model.utils.build_tensor_info(signature['ypreds'])}\n",
    "\n",
    "    prediction_signature = (tf.saved_model.signature_def_utils.build_signature_def(\n",
    "                              inputs=pred_inputs, outputs=pred_outputs,\n",
    "                              method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "    legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "    builder.add_meta_graph_and_variables(\n",
    "          sess, [tf.saved_model.tag_constants.SERVING],\n",
    "          signature_def_map={\n",
    "              'predict_instances': prediction_signature,\n",
    "              tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: classification_signature,\n",
    "          },\n",
    "          legacy_init_op=legacy_init_op)\n",
    "\n",
    "    builder.save()\n",
    "\n",
    "    model.export(export_path, IRIS_MODEL_NAME, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris_ml_experiment(learning_rate, epochs, batch_size):\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    hyperparams = { 'learning_rate': learning_rate, 'epochs': epochs, 'batch_size': batch_size }\n",
    "    \n",
    "    # load data\n",
    "    train_dataset, test_dataset, n_features, n_classes = load_data(hyperparams['batch_size'])\n",
    "    print('Loading data: DONE')\n",
    "\n",
    "    # create model\n",
    "    iris_model = create_model(n_features, n_classes)\n",
    "\n",
    "    # train model\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    metrics, signature = train_model(sess, iris_model, train_dataset, test_dataset, n_features, n_classes, hyperparams)\n",
    "    print('Training model: DONE')\n",
    "\n",
    "    # export model\n",
    "    export_model(sess, metrics, signature)\n",
    "    print('Exporting model: DONE')\n",
    "    \n",
    "    sess.close()\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def iris_ml_single_experiment():\n",
    "    learning_rate = 0.01\n",
    "    batch_size = 32\n",
    "    epochs = 1\n",
    "    \n",
    "    return iris_ml_experiment(learning_rate, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search dictionary\n",
    "hyperparams={'learning_rate': [0.01, 0.001, 0.02], 'batch_size': [32, 64, 128], 'epochs': [50, 75, 100] }\n",
    "\n",
    "# single experiment\n",
    "# experiment.launch(iris_ml_single_experiment, name='iris ml single experiment', metric_key=EVALUATION_METRIC)\n",
    "\n",
    "# grid search experiment\n",
    "experiment.grid_search(iris_ml_experiment, hyperparams, direction='max', name='iris ml experiment', optimization_key=EVALUATION_METRIC)\n",
    "\n",
    "# differential evolution\n",
    "# experiment.differential_evolution(iris_ml_experiment, hyperparams, direction=experiment.Direction.MAX, optimization_key='accuracy')\n",
    "# experiment.differential_evolution(\n",
    "#     iris_ml_experiment, \n",
    "#     hyperparams, \n",
    "#     direction='max',\n",
    "#     generations=4,\n",
    "#     population=5,                      \n",
    "#     name='iris ml experiment', \n",
    "#     optimization_key='accuracy',\n",
    "#     description='Demonstration of iris ml hyperparameters optimization',\n",
    "#     local_logdir=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serve the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Kafka topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_SCHEMA = { \"name\": \"inferencelog\", \"type\": \"record\", \"fields\": [\n",
    "    {\"name\": \"modelId\", \"type\": \"int\"},\n",
    "    {\"name\": \"modelName\", \"type\": \"string\"},\n",
    "    {\"name\": \"modelVersion\", \"type\": \"int\"},\n",
    "    {\"name\": \"requestTimestamp\", \"type\": \"long\"},\n",
    "    {\"name\": \"responseHttpCode\", \"type\": \"int\"},\n",
    "    {\"name\": \"inferenceResponse\", \"type\": \"string\"},\n",
    "    {\"name\": \"servingType\", \"type\": \"string\"}\n",
    "] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hops.exceptions import RestAPIError\n",
    "def create_kafka_topic(topic_name, topic_schema):\n",
    "    headers = {constants.HTTP_CONFIG.HTTP_CONTENT_TYPE: constants.HTTP_CONFIG.HTTP_APPLICATION_JSON}\n",
    "    method = constants.HTTP_CONFIG.HTTP_POST\n",
    "    resource_url = constants.DELIMITERS.SLASH_DELIMITER + \\\n",
    "                   constants.REST_CONFIG.HOPSWORKS_REST_RESOURCE + constants.DELIMITERS.SLASH_DELIMITER + \\\n",
    "                   constants.REST_CONFIG.HOPSWORKS_PROJECT_RESOURCE + constants.DELIMITERS.SLASH_DELIMITER + \\\n",
    "                   hdfs.project_id() + constants.DELIMITERS.SLASH_DELIMITER + \\\n",
    "                   constants.REST_CONFIG.HOPSWORKS_KAFKA_RESOURCE + constants.DELIMITERS.SLASH_DELIMITER + \\\n",
    "                   constants.REST_CONFIG.HOPSWORKS_SUBJECTS_RESOURCE + constants.DELIMITERS.SLASH_DELIMITER + \\\n",
    "                   topic_name + constants.DELIMITERS.SLASH_DELIMITER + \\\n",
    "                   \"versions\"\n",
    "\n",
    "    schema = { \"schema\" : topic_schema }\n",
    "    response = util.send_request(method, resource_url, data=json.dumps(schema), headers=headers)\n",
    "    response_object = response.json()\n",
    "    if response.status_code >= 400:\n",
    "        error_code, error_msg, user_msg = util._parse_rest_error(response_object)\n",
    "        raise RestAPIError(\"Could not perform action on job's execution (url: {}), server response: \\n \"\n",
    "                           \"HTTP code: {}, HTTP reason: {}, error code: {}, error msg: {}, user msg: {}\".format(\n",
    "            resource_url, response.status_code, response.reason, error_code, error_msg, user_msg))\n",
    "    return response_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** Replace with custom schema.\n",
    "\n",
    "> - Kafka topic creation via API is not currently working due to limited permission // HTTP code: 403, HTTP reason: Forbidden, error code: 200014, error msg: Token not issued for this recipient\n",
    "\n",
    "> - Add it manually via Hopsworks UI -> Copy paste the following schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fs_schema_to_avro_schema(fs_schema, field_name='fs_schema'):\n",
    "    fields = []\n",
    "    for feature in fs_schema:\n",
    "        fields.append({\"name\": feature['name'], \"type\": feature['type'].lower()})\n",
    "    return { \"name\": field_name, \"type\": { \"name\": field_name, \"type\": \"record\", \"fields\": fields } }\n",
    "\n",
    "def convert_tf_record_schema_to_spark_schema(tf_schema, spark_int_type=constants.SPARK_CONFIG.SPARK_INTEGER_TYPE,\n",
    "                                             spark_float_type=constants.SPARK_CONFIG.SPARK_DOUBLE_TYPE,\n",
    "                                             spark_string_type=constants.SPARK_CONFIG.SPARK_STRING_TYPE):\n",
    "    fields = []\n",
    "    for key in tf_schema.keys():    \n",
    "        tftype = tf_schema[key]\n",
    "    \n",
    "        # int - array(int)\n",
    "        if tftype.dtype ==  tf.FixedLenFeature([], tf.int64).dtype:\n",
    "            if tftype.shape == []:\n",
    "                fields.append({\"metadata\": {}, \"name\": key, \"nullable\": True, \"type\": spark_int_type})\n",
    "            else:\n",
    "                fields.append({\"metadata\": {}, \"name\": key, \"nullable\": True, \"type\": {\"containsNull\": True, \"elementType\": spark_int_type, \"type\": \"array\"}})\n",
    "            continue\n",
    "        if tftype.dtype == tf.VarLenFeature(tf.int64).dtype:\n",
    "            fields.append({\"metadata\": {}, \"name\": key, \"nullable\": True, \"type\": {\"containsNull\": True, \"elementType\": spark_int_type, \"type\": \"array\"}})\n",
    "            continue\n",
    "            \n",
    "        # float - array(float)\n",
    "        if tftype.dtype ==  tf.FixedLenFeature([], tf.float32).dtype:\n",
    "            if tftype.shape == []:\n",
    "                fields.append({\"metadata\": {}, \"name\": key, \"nullable\": True, \"type\": spark_float_type})\n",
    "            else:\n",
    "                fields.append({\"metadata\": {}, \"name\": key, \"nullable\": True, \"type\": {\"containsNull\": True, \"elementType\": spark_float_type, \"type\": \"array\"}})\n",
    "            continue\n",
    "        if tftype.dtype == tf.VarLenFeature(tf.float32).dtype:\n",
    "            fields.append({\"metadata\": {}, \"name\": key, \"nullable\": True, \"type\": {\"containsNull\": True, \"elementType\": spark_float_type, \"type\": \"array\"}})\n",
    "            continue\n",
    "        \n",
    "        # string - array(string)\n",
    "        # NOTE: VarLenFeature is used for both string and array(string) so real type cannot be inferred. We assume it is an array. Check \"_get_dataframe_tf_record_schema_json\" method.\n",
    "        if tftype.dtype == tf.VarLenFeature(tf.string).dtype:\n",
    "            fields.append({\"metadata\": {}, \"name\": key, \"nullable\": True, \"type\": {\"containsNull\": True, \"elementType\": spark_string_type, \"type\": \"array\"}})\n",
    "            continue\n",
    "    return { \"fields\": fields, \"type\": \"struct\" }\n",
    "\n",
    "def convert_spark_schema_to_avro_schema(s_schema, field_name='spark_schema'):\n",
    "    fields = []\n",
    "    for field in s_schema['fields']:\n",
    "        ftype = field['type']\n",
    "        fschema = { \"name\": field['name'] }\n",
    "        \n",
    "        if isinstance(ftype, str):\n",
    "            fschema['type'] = ftype\n",
    "        elif isinstance(ftype, dict):\n",
    "            if ftype['type'] == 'array':\n",
    "                fschema['type'] = ftype['type']\n",
    "                fschema['items'] = ftype['elementType']\n",
    "        fields.append(fschema)\n",
    "    return { \"name\": field_name, \"type\": { \"name\": field_name, \"type\": \"record\", \"fields\": fields } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avro schema from featurestore metadata:\n",
      " {'name': 'fs_schema', 'type': {'name': 'fs_schema', 'type': 'record', 'fields': [{'name': 'sepal_length', 'type': 'float'}, {'name': 'sepal_width', 'type': 'float'}, {'name': 'petal_length', 'type': 'float'}, {'name': 'petal_width', 'type': 'float'}, {'name': 'species', 'type': 'float'}]}} \n",
      "\n",
      "Avro schema from training dataset schema:\n",
      " {'name': 'inferenceRequest', 'type': {'name': 'inferenceRequest', 'type': 'record', 'fields': [{'name': 'sepal_length', 'type': 'double'}, {'name': 'sepal_width', 'type': 'double'}, {'name': 'petal_length', 'type': 'double'}, {'name': 'petal_width', 'type': 'double'}, {'name': 'species', 'type': 'double'}]}}"
     ]
    }
   ],
   "source": [
    "# get inference schema from featurestore metadata\n",
    "ds_version = 1\n",
    "fs_meta = featurestore.get_featurestore_metadata(featurestore=FS_NAME)\n",
    "fs_schema = [vars(f) for f in fs_meta.training_datasets[IRIS_TRAIN_DATASET_NAME + \"_\" + str(ds_version)].features]\n",
    "inference_request_schema = convert_fs_schema_to_avro_schema(fs_schema)\n",
    "print(\"Avro schema from featurestore metadata:\\n\", inference_request_schema, \"\\n\")\n",
    "\n",
    "# get inference schema from TFRecord schema\n",
    "tfrecord_schema = featurestore.get_training_dataset_tf_record_schema(IRIS_TRAIN_DATASET_NAME, featurestore=IRIS_FG_NAME)\n",
    "spark_schema = convert_tf_record_schema_to_spark_schema(tfrecord_schema)\n",
    "inference_request_schema_2 = convert_spark_schema_to_avro_schema(spark_schema, field_name='inferenceRequest')\n",
    "print(\"Avro schema from training dataset schema:\\n\", inference_request_schema_2,\"\\n\")\n",
    "\n",
    "# add to base schema\n",
    "TOPIC_SCHEMA[\"fields\"].append(inference_request_schema_2)\n",
    "TOPIC_SCHEMA = json.dumps(TOPIC_SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **IMPORTANT:** Create kafka topic not working API.\n",
    "\n",
    "> - Create kafka topic manually with the following parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name:  iris_ml_topic\n",
      "Schema:\n",
      " {\"name\": \"inferencelog\", \"type\": \"record\", \"fields\": [{\"name\": \"modelId\", \"type\": \"int\"}, {\"name\": \"modelName\", \"type\": \"string\"}, {\"name\": \"modelVersion\", \"type\": \"int\"}, {\"name\": \"requestTimestamp\", \"type\": \"long\"}, {\"name\": \"responseHttpCode\", \"type\": \"int\"}, {\"name\": \"inferenceResponse\", \"type\": \"string\"}, {\"name\": \"servingType\", \"type\": \"string\"}, {\"name\": \"inferenceRequest\", \"type\": {\"name\": \"inferenceRequest\", \"type\": \"record\", \"fields\": [{\"name\": \"sepal_length\", \"type\": \"double\"}, {\"name\": \"sepal_width\", \"type\": \"double\"}, {\"name\": \"petal_length\", \"type\": \"double\"}, {\"name\": \"petal_width\", \"type\": \"double\"}, {\"name\": \"species\", \"type\": \"double\"}]}}]}"
     ]
    }
   ],
   "source": [
    "# create kafka topic # NOT WORKING API\n",
    "# response = create_kafka_topic(IRIS_TOPIC_NAME, TOPIC_SCHEMA)\n",
    "# print(response)\n",
    "\n",
    "# COPY THROUGH HOPSWORKS UI\n",
    "print(\"Topic name: \", IRIS_TOPIC_NAME)\n",
    "print(\"Schema:\\n\", TOPIC_SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or update model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'EVALUATION_METRIC' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'EVALUATION_METRIC' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get best model\n",
    "best_model = model.get_best_model(IRIS_MODEL_NAME, EVALUATION_METRIC, Metric.MAX)\n",
    "\n",
    "print('Model name: ' + best_model['name'])\n",
    "print('Model version: ' + str(best_model['version']))\n",
    "print(best_model['metrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **IMPORTANT:** HTTP code: 400, HTTP reason: Bad Request, error code: 240010, error msg: Topic provided cannot be used for Serving logging, user msg: inferenceschema required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a serving for model Iris ...\n",
      "Serving for model Iris successfully created"
     ]
    }
   ],
   "source": [
    "# serve the model\n",
    "response = serving.create_or_update(MODELS_DIR, IRIS_MODEL_NAME, topic_name=IRIS_TOPIC_NAME, serving_type=\"TENSORFLOW\", model_version=best_model['version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Stopped'"
     ]
    }
   ],
   "source": [
    "# get serving status\n",
    "serving.get_status(IRIS_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting serving with name: Iris...\n",
      "Serving with name: Iris successfully started"
     ]
    }
   ],
   "source": [
    "if serving.get_status(IRIS_MODEL_NAME) == 'Stopped':\n",
    "    serving.start(IRIS_MODEL_NAME)\n",
    "\n",
    "import time\n",
    "time.sleep(10) # Let the serving startup correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on-demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instance():\n",
    "    sl = round(np.random.uniform(1,5), 1)\n",
    "    sw = round(np.random.uniform(1,4), 1)\n",
    "    pl = round(np.random.uniform(1,5), 1)\n",
    "    pw = round(np.random.uniform(1,3), 1)\n",
    "    return [sl, sw, pl, pw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Classification with scores\n",
      "Instance:  [2.8, 2.7, 1.4, 1.1]\n",
      "{'scores': [1.0, 0.0, 0.0], 'classes': ['0', '1', '2']}\n",
      "Instance:  [4.3, 2.1, 4.3, 2.3]\n",
      "{'scores': [0.999824, 0.000176003829, 1.79565079e-17], 'classes': ['2', '1', '0']}\n",
      "Instance:  [1.9, 1.9, 1.5, 1.6]\n",
      "{'scores': [1.0, 1.39763413e-24, 1.33207961e-26], 'classes': ['0', '2', '1']}\n",
      "\n",
      "# Direct classification\n",
      "Instance:  [3.6, 1.1, 1.6, 2.7]\n",
      "0\n",
      "Instance:  [1.9, 1.3, 1.7, 1.9]\n",
      "0\n",
      "Instance:  [3.0, 3.1, 3.8, 2.0]\n",
      "1"
     ]
    }
   ],
   "source": [
    "def batch_predictions(instances, signature_name):\n",
    "    instances = [generate_instance() for i in range(instances)]\n",
    "    data = { \"signature_name\": signature_name,\n",
    "             \"instances\": instances }\n",
    "    response = serving.make_inference_request(IRIS_MODEL_NAME, data)\n",
    "    for inst, pred in zip(instances, response['predictions']):\n",
    "        print(\"Instance: \", inst)\n",
    "        print(pred)\n",
    "\n",
    "print(\"# Classification with scores\")\n",
    "batch_predictions(3, tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY)\n",
    "    \n",
    "print(\"\\n# Direct classification\")\n",
    "batch_predictions(3, 'predict_instances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consuming predictions through Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from hops import kafka, tls\n",
    "from confluent_kafka import Consumer\n",
    "\n",
    "NUM_FEATURES = len(COL_NAMES)-1\n",
    "\n",
    "config = kafka.get_kafka_default_config()\n",
    "config['default.topic.config'] = {'auto.offset.reset': 'earliest'}\n",
    "topics = [IRIS_TOPIC_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = Consumer(config)\n",
    "consumer.subscribe(topics, on_assign = lambda _, partitions: print('Assignment:', partitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = kafka.get_schema(IRIS_TOPIC_NAME)\n",
    "avro_schema = kafka.convert_json_schema_to_avro(json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... timeout, no more messages to read from topic\n",
      "... timeout, no more messages to read from topic\n",
      "... timeout, no more messages to read from topic\n",
      "... timeout, no more messages to read from topic\n",
      "... timeout, no more messages to read from topic\n",
      "... timeout, no more messages to read from topic\n",
      "... timeout, no more messages to read from topic\n",
      "Assignment: [TopicPartition{topic=iris_ml_topic,partition=0,offset=-1001,error=None}]\n",
      "serving: Iris, version: 58, timestamp: 1581515022883,\n",
      "request: {\"signature_name\": \"serving_default\", \"instances\": [[2.8, 2.7, 1.4, 1.1], [4.3, 2.1, 4.3, 2.3], [1.9, 1.9, 1.5, 1.6]]},\n",
      "prediction: {'scores': [1.0, 0.0, 0.0], 'classes': ['0', '1', '2']}, http_response_code: 200, serving_type: TENSORFLOW\n",
      "\n",
      "serving: Iris, version: 58, timestamp: 1581515023045,\n",
      "request: {\"signature_name\": \"predict_instances\", \"instances\": [[3.6, 1.1, 1.6, 2.7], [1.9, 1.3, 1.7, 1.9], [3.0, 3.1, 3.8, 2.0]]},\n",
      "prediction: 0, http_response_code: 200, serving_type: TENSORFLOW\n",
      "\n",
      "... timeout, no more messages to read from topic"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    msg = consumer.poll(timeout=1.0)\n",
    "    if msg is not None:\n",
    "        value = msg.value()\n",
    "        try:\n",
    "            event_dict = kafka.parse_avro_msg(value, avro_schema)\n",
    "            prediction = json.loads(event_dict[\"inferenceResponse\"])[\"predictions\"][0]\n",
    "            print(\"serving: {}, version: {}, timestamp: {},\"\\\n",
    "                  \"\\nrequest: {},\\nprediction: {}, http_response_code: {},\"\\\n",
    "                  \" serving_type: {}\\n\".format(\n",
    "                       event_dict[\"modelName\"],\n",
    "                       event_dict[\"modelVersion\"],\n",
    "                       event_dict[\"requestTimestamp\"],\n",
    "                       event_dict[\"inferenceRequest\"],\n",
    "                       prediction,\n",
    "                       event_dict[\"responseHttpCode\"],\n",
    "                       event_dict[\"servingType\"]))\n",
    "        except Exception as e:\n",
    "            print(\"A message was read but there was an error parsing it\")\n",
    "            print(e)\n",
    "    else:\n",
    "        print(\"... timeout, no more messages to read from topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from io import BytesIO, StringIO\n",
    "# from avro.io import DatumReader, BinaryDecoder\n",
    "# import avro.schema\n",
    "    \n",
    "# print(\"\\nVALUE:\")\n",
    "# print(value)\n",
    "\n",
    "# print(\"\\nCustom schema:\")\n",
    "# custom_avro_schema = kafka.convert_json_schema_to_avro(avro_type_struct)\n",
    "# print(custom_avro_schema)\n",
    "\n",
    "# base_avro_schema = kafka.convert_json_schema_to_avro(base_avro_type_struct)\n",
    "# print(base_avro_schema)\n",
    "\n",
    "# print(\"\\nRequest:\")\n",
    "# reader = DatumReader(base_avro_schema)\n",
    "# message_bytes = BytesIO(value)\n",
    "# decoder = BinaryDecoder(message_bytes)\n",
    "# request = reader.read(decoder)\n",
    "# print(request['inferenceRequest'])\n",
    "# print(type(json.loads(request['inferenceRequest'])['instances'][0][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}